{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "\n",
    "A perceptron takes in multiple binary inputs $x_1, x_2, ..., x_n$ and returns a binary output.  \n",
    "  \n",
    "This means that a perceptron is a map $f: \\mathbb{Z}^n_2 \\rightarrow \\mathbb{Z}_2$ . \n",
    "  \n",
    "In order to convert these binary inputs into a binary ouput we use weights. $w_1, w_2, ..., w_n$ where $w_j \\in \\mathbb{R}$. These weights are used to scale the inputs then summed to determine what the output should be based on if they are above or below a defined threshold.  \n",
    "  \n",
    "output = $\\begin{cases} \\text{0    if } \\Sigma_j w_j x_j \\leq \\text{threshold} \\\\ \\text{1    if } \\Sigma_j w_j x_j > \\text{threshold} \\end{cases}$ . \n",
    "  \n",
    "So the aim is to use the degrees of freedom given by the weights and the thresholds to come up with a model to make our decisions.  \n",
    "  \n",
    "### Network of perceptons \n",
    "  \n",
    "To make the percepton model more plausible in it's decision making we mimic the approach that the brain uses. So we come up with layers of connected perceptons, which allows for ever more subtle and complex decisions to be made in later layers. When we consider the first layer all it can do is a dot product so can't model very complex deccisions. Yet by taking the output of this first layer and passing them into the input as a second layer allows the second layer to produce more complex decisions.  \n",
    "  \n",
    "### Mathmatical tidy up  \n",
    "  \n",
    "Previously spoke about the arbitary threshold, the more colloquial way to describe this is a bias where $b \\equiv -\\text{threshold}$ . \n",
    "  \n",
    "This means we can rewrite the previous equation as:  \n",
    "  \n",
    "output = $\\begin{cases} \\text{0    if } w \\cdot x + b \\leq 0\\\\ \\text{1    if } w \\cdot x + b > 0 \\end{cases}$ ."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
